---
title: 'LLM Paper Abstract - 2023.11'
author: [Soohwan Kim]
tags: [nlp]
image: img/llm-abs-202310.jpg
date: '2023-12-05T10:00:00.000Z'
draft: false
---
  
# LLM Paper Abstract - 2023.11
  
LLM 관련해서 워낙 많은 논문들이 나와서, 최근에 읽은 논문들에 대해 간단하게 요약한 리스트입니다.  
아래 리스트중에는 가볍게 읽어본 논문들이 포함되어 있어서 요약에 틀린 내용이 있을 수 있습니다.
  
## Abstract

### 11월 4주차

- [**`Orca 2: Teaching Small Language Models How to Reason`**](https://arxiv.org/abs/2311.11045) : 마이크로소프트에서 공개한 Orca-2 모델 관련 논문. 7B, 13B 모델의 reasoning 능력을 개선해보려는 시도와 결과에 대해 리포트 함.

- [**`LLM-ASSISTED CODE CLEANING FOR TRAINING ACCURATE CODE GENERATORS`**](https://arxiv.org/abs/2311.14904) : 코드 생성 AI를 학습시킬때, 리팩토링을 통해 코드 가독성을 높인 코드로 학습시키면 모델 성능이 크게 좋아진다는 논문.

- [**`ChatGPT’s One-year Anniversary: Are Open-Source Large Language Models Catching up?`**](https://arxiv.org/abs/2311.16989) : ChatGPT 1주년 기념으로, 오픈소스 LLM들이 ChatGPT, GPT4들을 얼마나 따라잡았는지를 평가한 논문

- [**`Scaling deep learning for materials discovery`**](https://www.nature.com/articles/s41586-023-06735-9) : Google DeepMind 논문에서 신소재 검색을 위한 AI 모델 ‘GNoME’을 통해 38만개의 신소재를 발견했다는 논문. 그동안 인류가 발견했던 2만개와 비교하면 20배에 달하는 능력이라고..

### 11월 3주차

- [**`Contrastive Chain-of-Thought Prompting`**](https://arxiv.org/abs/2311.09277) : CoT의 한계를 지적한 논문. CoT가 비록 논리적인 추론에 대해서 중요한 부분이긴 하지만, 프롬프트 작성 시에 잘못 작성 했을 시에 대해 피할 수 없고, 이에 따라 많은 오류를 발생시킴. 따라서 instruction에 대한 negative sample과 positive sample을 동시에 입력으로 넣어 contrastive한 방식으로 추론할 수 있는 기법을 만들어낸 논문.

### 11월 2주차

- [**`Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models`**](https://arxiv.org/abs/2311.09210) : Retrieval-augmented language models에서 정확한 정보를 retrieval해도 아직 부족한 점이 많다는 점에서 나온 논문. Chain-of-Noting(CoN)이라는 방식을 활용하여서 retrieval된 도큐먼트에 대한 순차적인 읽기를 생성해서 질문과의 연관성을 평가하여 최종 답변을 도출한다는 논문. RAG 분야 성능을 높이려고 노력한 논문.

- [**`Pretraining Data Mixtures Enable Narrow Model Selection Capabilities in Transformer Models`**](https://arxiv.org/abs/2311.00871) : 추론 시 사전학습된 데이터의 distribution과 너무 차이가 나는 prediction은 잘 하지 못한다는 내용의 논문. 즉 in-context learning은 학습 데이터와 많이 차이 나지 않는 distribution 범위에서만 가능하다는 논문. 
  
- [**`Large Language Model as Attributed Training Data Generator: A Tale of Diversity and Bias`**](https://arxiv.org/abs/2306.15895) : ChatGPT와 같은 LLM을 데이터 생성에 사용하는 법에 관련한 논문. 다양성과 편향에 대해서도 같이 다룸.

- [**`Levels of AGI: Operationalizing Progress on the Path to AGI`**](https://arxiv.org/abs/2311.02462) : 구글, 딥마인드에서 AI 능력을 5단계로 구분하고 레벨을 매겨 AGI로 가는 길에 대해 제시한 논문. 내용 자체는 뻔한 내용. ChatGPT를 1단계로 설정.

- [**`SIMPLIFYING TRANSFORMER BLOCKS`**](https://arxiv.org/abs/2311.01906) : 트랜스포머 구조를 단순화하여 15%의 학습 속도 개선과 15%의 파라미터를 줄이는 방향으로 개선안을 제안한 논문.

- [**`ChatGPT is fun, but it is not funny! Humor is still challenging Large Language Models`**](https://arxiv.org/abs/2306.04563) : ChatGPT의 Joke에 관련한 논문. ChatGPT가 Joke를 잘하는듯 보이지만, 사실 ChatGPT가 하는 대부분(90%)의 joke가 25개의 joke에 한정되어있다고 함.

- [**`EXTRAPOLATING LARGE LANGUAGE MODELS TO NON-ENGLISH BY ALIGNING LANGUAGES`**](https://arxiv.org/abs/2308.04948) : LLaMA에서 non-english 능력을 이끌어내기 위한 방법에 대해 제시한 논문. 번역 태스크로 instruction 튜닝을 하는 등의 방법을 사용함.

- [**`S-LORA: SERVING THOUSANDS OF CONCURRENT LORA ADAPTERS`**](https://arxiv.org/abs/2311.03285v2) : LoRA Adapter가 여러개일 때 서빙하는 방법에 대한 논문.

- [**`Rephrase and Respond: Let Large Language Models Ask Better Questions for Themselves`**](https://arxiv.org/abs/2311.04205) : LLM에게 질문을 rephrase 시키고 답변시켰을 때 더 좋은 결과가 있었다는 논문.

### 11월 1주차

- [**`YaRN: Efficient Context Window Extension of Large Language Models`**](https://arxiv.org/abs/2309.00071) : YaRN(Yet another RoPE extensioN method)이라는 Rotary Embedding을 개선한 버전을 제안한 논문. 기존 pre-training시 사용한 max length보다 더 길게 확장할 수 있음을 보임 (LLaMA를 128k 토큰까지 확장)
