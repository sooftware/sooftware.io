{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/2020 EMNLP Speech Paper Review/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>EMNLP Paper Review: Speech</h1>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2010.08518\">Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al)</a></li>\n<li><a href=\"https://arxiv.org/abs/1911.02750\">Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework (Mingbo Ma et al)</a></li>\n</ul>\n<h2>Adaptive Feature Selection for End-to-End Speech Translation</h2>\n<ul>\n<li>EMNLP 2020</li>\n<li>Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich</li>\n</ul>\n<h3>Summary</h3>\n<ul>\n<li>End-to-End Speech Translation (E2E ST)ë¥¼ ë‹¤ë£¬ ë…¼ë¬¸</li>\n<li>Speech Translation\n<ul>\n<li>Cascade: ìŒì„± (source) â†’ ìŒì„±ì¸ì‹ ëª¨ë¸ â†’ í…ìŠ¤íŠ¸ (source) â†’ ë²ˆì—­ ëª¨ë¸ â†’ í…ìŠ¤íŠ¸ (target)</li>\n<li>E2E: ìŒì„± (source) â†’ ìŒì„±ë²ˆì—­ ëª¨ë¸ â†’ í…ìŠ¤íŠ¸ (target)</li>\n</ul>\n</li>\n<li>Cascade ë°©ì‹ì€ ìŒì„±ì¸ì‹ì—ì„œì˜ ì˜¤ë¥˜ê°€ ê¸°ê³„ë²ˆì—­ìœ¼ë¡œ ì „íŒŒê°€ ë˜ëŠ” ë‹¨ì ì´ ìˆìŒ</li>\n<li>E2E ë²ˆì—­ì´ ìµœê·¼ ë§ì´ ì—°êµ¬ë˜ê³  ìˆìœ¼ë‚˜, Cascade ë°©ì‹ì˜ ì„±ëŠ¥ì„ ë”°ë¼ì¡ì§€ ëª»í•˜ê³  ìˆìŒ</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101368190-32294400-38ea-11eb-924b-5b0a2e25d2e6.png\" alt=\"image\"></p>\n<ul>\n<li>E2E STê°€ ì–´ë ¤ìš´ ì£¼ëœ ì´ìœ ë¡œ, ìŒì„±ë§ˆë‹¤ ë‹¨ì–´ ë°œí™” ê¸¸ì´ê°€ ë‹¤ë¥´ë©°, ë…¸ì´ì¦ˆ í˜¹ì€ ì¤‘ê°„ì¤‘ê°„ ëŠê¸°ëŠ” ë“± ì¼ê´€ì ì´ì§€ ì•Šë‹¤ëŠ” íŠ¹ì§• ë•Œë¬¸ì´ë¼ê³  ì£¼ì¥</li>\n<li>ê·¸ë˜ì„œ ì¸ì½”ë”© ëœ í”¼ì³ë¥¼ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©í•´ì•¼ ëœë‹¤ê³  ì£¼ì¥ (Adaptive Feature Selection)</li>\n<li>AFSëŠ” ì¸ì½”ë” ì•„ì›ƒí’‹ì—ì„œ í•„ìš”ì—†ëŠ” í”„ë ˆì„ì€ ì œê±°í•˜ëŠ” ì—­í• ì„ í•¨ (L<sub>0</sub>Drop - Zhang et al., 2020)</li>\n<li>ê²°ê³¼ì ìœ¼ë¡œ ë³¸ ë…¼ë¬¸ì€ ì•„ë˜ì™€ ê°™ì€ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•¨</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/101366218-073df080-38e8-11eb-8699-dd6ebc2d70dc.png\" width=\"300\">  \n<ul>\n<li>Training Pipeline\n<ol>\n<li>ASR ëª¨ë¸ í•™ìŠµ (Hybrid Cross Entropy + CTC)</li>\n<li>AFS ëª¨ë¸ì„ ì¶”ê°€í•´ì„œ ASR ëª¨ë¸ íŒŒì¸íŠœë‹</li>\n<li>ASR &#x26; AFS ëª¨ë¸ì€ Freezeí•œ ì±„ë¡œ ST Encoder, ST Decoder í•™ìŠµ</li>\n</ol>\n</li>\n<li>Result on MuST-C En-De</li>\n</ul>\n<img src=\"https://user-images.githubusercontent.com/42150335/101370007-4a9a5e00-38ec-11eb-8f41-7f6de1b9d583.png\" width=\"500\">\n<ul>\n<li>AFSëŠ” ëª¨ë¸ì„ ë” ë¹ ë¥´ê²Œ í•˜ë©´ì„œë„ ì„±ëŠ¥ì„ ë†’ì˜€ìŒ</li>\n<li>ì„±ëŠ¥ì€ Cascadeë³´ë‹¤ëŠ” ì‚´ì§ ë‚®ìŒ</li>\n</ul>\n<hr>\n<h2>Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework</h2>\n<ul>\n<li>EMNLP 2020</li>\n<li>Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan Peng, Kenneth Church, Liang Huang  (Baidu Research)</li>\n<li><a href=\"https://inctts.github.io/\">Demo Page</a></li>\n</ul>\n<h3>Summary</h3>\n<ul>\n<li>ë™ì‹œë²ˆì—­ì„ ìœ„í•œ ë¹ ë¥¸ ìŒì„±í•©ì„± ê¸°ë²• ì œì•ˆ</li>\n<li>ìƒˆë¡œ í•™ìŠµí•  í•„ìš”ì—†ì´ Inference ë‹¨ì—ì„œ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŒŒì´í”„ë¼ì¸ ì œì•ˆ (Tacotron2 ì‚¬ìš©)</li>\n<li>ê¸°ì¡´ TTS ì‹œìŠ¤í…œ</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101376816-6bff4800-38f4-11eb-9dca-1592c05c6759.png\" alt=\"image\"></p>\n<p>Text2Phoneme â†’ Phoneme2Spectrogram â†’ Spectrogram2Wave ë‹¨ê³„ë¥¼ ê±°ì¹¨</p>\n<ul>\n<li>ìœ„ì™€ ê°™ì€ Full-sentence TTSëŠ” ë¬¸ì¥ ê¸¸ì´ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ latencyê°€ ê¸¸ì–´ì§€ëŠ” ê³ ì§ˆì ì¸ ë¬¸ì œì ì„ ê°€ì§€ê³  ìˆìŒ</li>\n<li>ì´ëŸ¬í•œ ë¬¸ì œì  í•´ê²°ì„ ìœ„í•´ ì•„ë˜ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆ</li>\n</ul>\n<p><img src=\"https://user-images.githubusercontent.com/42150335/101377884-bf25ca80-38f5-11eb-8098-6f0b206d01f6.png\" alt=\"image\"></p>\n<ul>\n<li>Full-sentence TTSê°€ ì•„ë‹Œ, Incremental TTS ë°©ì‹ ì œì•ˆ</li>\n<li>ë¨¼ì € ë§Œë“¤ì–´ì§„ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ëŠ” ë™ì•ˆ ë’·ë‹¨ì˜ ì˜¤ë””ì˜¤ë¥¼ ë§Œë“¤ì–´ë‚˜ê°€ëŠ” ë°©ì‹</li>\n<li>ì´ì™€ ê°™ì€ íŒŒì´í”„ë¼ì¸ì´ ê°€ëŠ¥í•˜ë ¤ë©´ íŠ¹ì • ë‹¨ìœ„ë¡œ ìª¼ê°œì•¼í•¨ (E.g. Word)</li>\n<li>í•˜ì§€ë§Œ Word ë‹¨ìœ„ë¡œ TTSë¥¼ ì§„í–‰í•œ í›„, ì˜¤ë””ì˜¤ë¥¼ ì´ì–´ë¶™ì´ê²Œ ë˜ë©´ êµ‰ì¥íˆ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì´ í•©ì„±ë¨</li>\n<li>ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ lookahead-k Policy ì œì•ˆ\n<ul>\n<li>të²ˆì§¸ targetì„ ë§Œë“¤ë•Œ t+kê°œì˜ ì…ë ¥ ì†ŒìŠ¤ë¥¼ í†µí•´ ìƒì„± (ì²« k+1 ìŠ¤í…ê¹Œì§€ëŠ” wait)</li>\n</ul>\n</li>\n<li>ê²°ê³¼ì ìœ¼ë¡œ ìŒì§ˆì´ í¬ê²Œ ë–¨ì–´ì§€ì§€ ì•Šìœ¼ë©´ì„œë„ latencyë¥¼ ì¤„ì„ (ë¬¸ì¥ì´ ê¸¸ìˆ˜ë¡ íš¨ê³¼ê°€ í¼)</li>\n</ul>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"EMNLP Paper Review: Speech"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/2010.08518"},"children":[{"type":"text","value":"Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al)"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/1911.02750"},"children":[{"type":"text","value":"Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework (Mingbo Ma et al)"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Adaptive Feature Selection for End-to-End Speech Translation"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"EMNLP 2020"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Biao Zhang, Ivan Titov, Barry Haddow, Rico Sennrich"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Summary"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"End-to-End Speech Translation (E2E ST)ë¥¼ ë‹¤ë£¬ ë…¼ë¬¸"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Speech Translation\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Cascade: ìŒì„± (source) â†’ ìŒì„±ì¸ì‹ ëª¨ë¸ â†’ í…ìŠ¤íŠ¸ (source) â†’ ë²ˆì—­ ëª¨ë¸ â†’ í…ìŠ¤íŠ¸ (target)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E: ìŒì„± (source) â†’ ìŒì„±ë²ˆì—­ ëª¨ë¸ â†’ í…ìŠ¤íŠ¸ (target)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Cascade ë°©ì‹ì€ ìŒì„±ì¸ì‹ì—ì„œì˜ ì˜¤ë¥˜ê°€ ê¸°ê³„ë²ˆì—­ìœ¼ë¡œ ì „íŒŒê°€ ë˜ëŠ” ë‹¨ì ì´ ìˆìŒ"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E ë²ˆì—­ì´ ìµœê·¼ ë§ì´ ì—°êµ¬ë˜ê³  ìˆìœ¼ë‚˜, Cascade ë°©ì‹ì˜ ì„±ëŠ¥ì„ ë”°ë¼ì¡ì§€ ëª»í•˜ê³  ìˆìŒ"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101368190-32294400-38ea-11eb-924b-5b0a2e25d2e6.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"E2E STê°€ ì–´ë ¤ìš´ ì£¼ëœ ì´ìœ ë¡œ, ìŒì„±ë§ˆë‹¤ ë‹¨ì–´ ë°œí™” ê¸¸ì´ê°€ ë‹¤ë¥´ë©°, ë…¸ì´ì¦ˆ í˜¹ì€ ì¤‘ê°„ì¤‘ê°„ ëŠê¸°ëŠ” ë“± ì¼ê´€ì ì´ì§€ ì•Šë‹¤ëŠ” íŠ¹ì§• ë•Œë¬¸ì´ë¼ê³  ì£¼ì¥"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ê·¸ë˜ì„œ ì¸ì½”ë”© ëœ í”¼ì³ë¥¼ ì„ íƒì ìœ¼ë¡œ ì‚¬ìš©í•´ì•¼ ëœë‹¤ê³  ì£¼ì¥ (Adaptive Feature Selection)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFSëŠ” ì¸ì½”ë” ì•„ì›ƒí’‹ì—ì„œ í•„ìš”ì—†ëŠ” í”„ë ˆì„ì€ ì œê±°í•˜ëŠ” ì—­í• ì„ í•¨ (L"},{"type":"element","tagName":"sub","properties":{},"children":[{"type":"text","value":"0"}]},{"type":"text","value":"Drop - Zhang et al., 2020)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ê²°ê³¼ì ìœ¼ë¡œ ë³¸ ë…¼ë¬¸ì€ ì•„ë˜ì™€ ê°™ì€ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆí•¨"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101366218-073df080-38e8-11eb-8699-dd6ebc2d70dc.png","width":300},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Training Pipeline\n"},{"type":"element","tagName":"ol","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR ëª¨ë¸ í•™ìŠµ (Hybrid Cross Entropy + CTC)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFS ëª¨ë¸ì„ ì¶”ê°€í•´ì„œ ASR ëª¨ë¸ íŒŒì¸íŠœë‹"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR & AFS ëª¨ë¸ì€ Freezeí•œ ì±„ë¡œ ST Encoder, ST Decoder í•™ìŠµ"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Result on MuST-C En-De"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101370007-4a9a5e00-38ec-11eb-8f41-7f6de1b9d583.png","width":500},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"AFSëŠ” ëª¨ë¸ì„ ë” ë¹ ë¥´ê²Œ í•˜ë©´ì„œë„ ì„±ëŠ¥ì„ ë†’ì˜€ìŒ"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ì„±ëŠ¥ì€ Cascadeë³´ë‹¤ëŠ” ì‚´ì§ ë‚®ìŒ"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"hr","properties":{},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Incremental Text-to-Speech Synthesis with Prefix-to-Prefix Framework"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"EMNLP 2020"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Mingbo Ma, Baigong Zheng, Kaibo Liu, Renjie Zheng, Hairong Liu, Kainan Peng, Kenneth Church, Liang Huang  (Baidu Research)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://inctts.github.io/"},"children":[{"type":"text","value":"Demo Page"}]}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h3","properties":{},"children":[{"type":"text","value":"Summary"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ë™ì‹œë²ˆì—­ì„ ìœ„í•œ ë¹ ë¥¸ ìŒì„±í•©ì„± ê¸°ë²• ì œì•ˆ"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ìƒˆë¡œ í•™ìŠµí•  í•„ìš”ì—†ì´ Inference ë‹¨ì—ì„œ ìˆ˜ì •í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” íŒŒì´í”„ë¼ì¸ ì œì•ˆ (Tacotron2 ì‚¬ìš©)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ê¸°ì¡´ TTS ì‹œìŠ¤í…œ"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101376816-6bff4800-38f4-11eb-9dca-1592c05c6759.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"text","value":"Text2Phoneme â†’ Phoneme2Spectrogram â†’ Spectrogram2Wave ë‹¨ê³„ë¥¼ ê±°ì¹¨"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ìœ„ì™€ ê°™ì€ Full-sentence TTSëŠ” ë¬¸ì¥ ê¸¸ì´ê°€ ê¸¸ì–´ì§ˆìˆ˜ë¡ latencyê°€ ê¸¸ì–´ì§€ëŠ” ê³ ì§ˆì ì¸ ë¬¸ì œì ì„ ê°€ì§€ê³  ìˆìŒ"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ì´ëŸ¬í•œ ë¬¸ì œì  í•´ê²°ì„ ìœ„í•´ ì•„ë˜ íŒŒì´í”„ë¼ì¸ì„ ì œì•ˆ"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"p","properties":{},"children":[{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/101377884-bf25ca80-38f5-11eb-8098-6f0b206d01f6.png","alt":"image"},"children":[]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Full-sentence TTSê°€ ì•„ë‹Œ, Incremental TTS ë°©ì‹ ì œì•ˆ"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ë¨¼ì € ë§Œë“¤ì–´ì§„ ì˜¤ë””ì˜¤ë¥¼ ì¬ìƒí•˜ëŠ” ë™ì•ˆ ë’·ë‹¨ì˜ ì˜¤ë””ì˜¤ë¥¼ ë§Œë“¤ì–´ë‚˜ê°€ëŠ” ë°©ì‹"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ì´ì™€ ê°™ì€ íŒŒì´í”„ë¼ì¸ì´ ê°€ëŠ¥í•˜ë ¤ë©´ íŠ¹ì • ë‹¨ìœ„ë¡œ ìª¼ê°œì•¼í•¨ (E.g. Word)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"í•˜ì§€ë§Œ Word ë‹¨ìœ„ë¡œ TTSë¥¼ ì§„í–‰í•œ í›„, ì˜¤ë””ì˜¤ë¥¼ ì´ì–´ë¶™ì´ê²Œ ë˜ë©´ êµ‰ì¥íˆ ë¶€ìì—°ìŠ¤ëŸ¬ìš´ ìŒì„±ì´ í•©ì„±ë¨"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ì´ë¥¼ ê·¹ë³µí•˜ê¸° ìœ„í•´ lookahead-k Policy ì œì•ˆ\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"të²ˆì§¸ targetì„ ë§Œë“¤ë•Œ t+kê°œì˜ ì…ë ¥ ì†ŒìŠ¤ë¥¼ í†µí•´ ìƒì„± (ì²« k+1 ìŠ¤í…ê¹Œì§€ëŠ” wait)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ê²°ê³¼ì ìœ¼ë¡œ ìŒì§ˆì´ í¬ê²Œ ë–¨ì–´ì§€ì§€ ì•Šìœ¼ë©´ì„œë„ latencyë¥¼ ì¤„ì„ (ë¬¸ì¥ì´ ê¸¸ìˆ˜ë¡ íš¨ê³¼ê°€ í¼)"}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speechâ€¦","fields":{"readingTime":{"text":"4 min read"}},"frontmatter":{"title":"EMNLP Paper Review: Speech","userDate":"8 December 2020","date":"2020-12-08T10:00:00.000Z","tags":["speech","nlp","paper"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png","srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/1206c/2020-emnlp.png 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c1998/2020-emnlp.png 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c6087/2020-emnlp.png 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/3e1c3/2020-emnlp.webp 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/bbc54/2020-emnlp.webp 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/72682/2020-emnlp.webp 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/97f4c/2020-emnlp.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.41875}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/f31ef/ghost.png 40w,\n/static/7ffe238930a689e103d70f234bb00199/1f8a1/ghost.png 80w,\n/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/e73fe/ghost.webp 40w,\n/static/7ffe238930a689e103d70f234bb00199/61ca6/ghost.webp 80w,\n/static/7ffe238930a689e103d70f234bb00199/507b0/ghost.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}]}}]}},"relatedPosts":{"totalCount":13,"edges":[{"node":{"id":"f2f95a99-ae13-5b3f-9375-508975c97e83","excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLMâ€¦","frontmatter":{"title":"Textless NLP","date":"2021-09-19T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/Textledd NLP: Generating expressive speech from raw audio/"}}},{"node":{"id":"19ded62e-3e91-5733-9329-a1c7bdcf859b","excerpt":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Yu Zhang et al., 2020 Google Research, Brain Team Referenceâ€¦","frontmatter":{"title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Paper Review","date":"2021-03-17T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition/"}}},{"node":{"id":"35eadfc7-646b-5194-a711-ce20e840ba58","excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speechâ€¦","frontmatter":{"title":"EMNLP Paper Review: Speech","date":"2020-12-08T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/2020 EMNLP Speech Paper Review/"}}},{"node":{"id":"fd3185b8-63e4-5e3d-aeb3-e67ed1343af9","excerpt":"One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech TomÃ¡Å¡ Nekvinda, OndÅ™ej DuÅ¡ek Charles University INTERSPEECH, 202â€¦","frontmatter":{"title":"One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech Paper Review","date":"2020-10-14T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/one-model-many-langs/"}}},{"node":{"id":"aad087b1-4b0f-5956-ab2f-d7ab33fdb8c4","excerpt":"wav2vec 2.0 : A Framework for Self-Supervised Learning of Speech Representations Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michaelâ€¦","frontmatter":{"title":"Wav2vec 2.0 : A Framework for Self-Supervised Learning of Speech Representations","date":"2020-09-12T10:00:00.000Z"},"fields":{"readingTime":{"text":"5 min read"},"slug":"/wav2vec2/"}}}]}},"pageContext":{"slug":"/2020 EMNLP Speech Paper Review/","prev":{"excerpt":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism â€‹ Mohammad Shoeybi et al. 2019. NVIDIA Corp. â€‹ Summaryâ€¦","frontmatter":{"title":"Megatron LM Paper Review","tags":["nlp","parallelism","paper"],"date":"2020-12-03T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAKCAYAAAC0VX7mAAAACXBIWXMAAAsTAAALEwEAmpwYAAACbUlEQVQoz32SyWoUcRDG21fw7hv4CoKCXvWgJ3FDEfTsQVEQRcnBgHgU8aASJaK4RaMXQ7ZZepnee3qZ7p7uSSbp6TRJnAE1OOTn/6IHDxYUVVR9X1EfVdL29haqquCabSzToSlrqM0mzVqNlqGjqCpVWTEaDjFELoueqqgoTRVTs5lfWqTeaOB4DuPxGMmybGRZZVZ7hR+1SAMFL0kxopDAMFEaNWpqHdOymJNlzLZHEIdoboNZ9TWhbuHoOq2aTrFeIHmuTui6XPl6jLr9gm1riv0bFXvLPsanGvcXbnC+fZaPSgep6HO0a3Kxd5oP3hR36ucYezld0+CZ/5x8LUPK3Hck5heufz2LlXxhlC7yYDji1lZFojrMtl7y2H+E7MZc6q/weC3l/dYbFpIZ7jUuUyptXKXJofwwwSBAyt23pNZnbsydI1hdZKfyKX+N6f34ziBOCdsWWtAiiDooWUa2ucH38U/M9QXuzl9kpWZi1pc5kB0kKMXAMLDIooir88dputMM7Sn2lRvsWc+xPjeYXLrGmfAks7qQM1jjSGZwqneCGSFxQrkgJPfIHYub+W26RYrkBwGh3+GpOknckxmtyLz+NuTJZkXacpjTZnjpTKM6IRNpwtuVhPlqDntV4JyHDDtiYOATOTHF2jqSYRgoikw3zomErLCTsJnn9P2AOIlxDAejYWDoLSLxLkU3E16QdXPMloUu+FGnw9LyIv1+H6ksSzRNw3EdXHFtz3OxRdQE0PM8QdAZbAwYjUYo4j0cUfN8D19sVW/UxTIKtm1j2RY7OztI/Md2d3cpioI4jjFNk6qq/tb/xf2x39lGqyQia/HFAAAAAElFTkSuQmCC"},"images":{"fallback":{"src":"/static/a4dec0b9c36035e9191658ce9647ae73/a70e6/megatron.png","srcSet":"/static/a4dec0b9c36035e9191658ce9647ae73/37b55/megatron.png 750w,\n/static/a4dec0b9c36035e9191658ce9647ae73/a70e6/megatron.png 791w","sizes":"100vw"},"sources":[{"srcSet":"/static/a4dec0b9c36035e9191658ce9647ae73/0b2ce/megatron.webp 750w,\n/static/a4dec0b9c36035e9191658ce9647ae73/c471e/megatron.webp 791w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5170670037926676}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAABCUlEQVQ4y2MQVdQiGzEMJ80iCppwBOcSpRlZHZop+DSLKWnzS6v0Tpl5/da9E2cuXL1xZ/6SlXxSyvOXrlq8cp2ArBpBzaqNnX1HT57Zvmf/4ROnJk6fwyutMnHG3GlzFgri1wxBAjKqQPthSBXoYIgIUc7umTT96vVbJ06fO3X2AhABGZev3Zgxb5GwvAYhzTJAZ/cfPXF2595Duw8cASIg4/Dx072TZxLQjOFsVTCCeoEoZ3dPnH7l2q1zF6+6BYSbO3mdPnfp8tWb0+cuEiLsbGnV5q4Jx8+cO3TspLNviKmD+/4jx4+dPtc/bRZRzhaSUxeUUwMioGphBU0IW1BOfZjnKnpoBgBuRuAIvQwT7gAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/Megatron-lm/"}},"next":{"excerpt":"2020ë…„ íšŒê³  ë‹¤ì‚¬ë‹¤ë‚œí–ˆë˜ 2020ë…„ì´ ì§€ë‚˜ê³  ì–´ëŠë§ 2021ë…„ ìƒˆí•´ê°€ ë°ì•˜ìŠµë‹ˆë‹¤. ğŸ¤— ğŸ¤— ì½”ë¡œë‚˜ë¼ëŠ” ì„¸ê³„ì ì¸ ì¬ì•™ ë•Œë¬¸ì— ìƒí™œë¶€í„° ëª¨ë“ ê²Œ ë§ì´ ë‹¬ë¼ì§„ í•œ í•´ ì˜€ìŠµë‹ˆë‹¤. ì—¬íƒœê¹Œì§€â€¦","frontmatter":{"title":"2020ë…„ íšŒê³ ","tags":["retrospect"],"date":"2020-12-31T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAANCAYAAACpUE5eAAAACXBIWXMAAAsTAAALEwEAmpwYAAADOklEQVQ4yzWT+0/TVxjGv1QCIZQKThYXtVAuhSlliw4LXuYgEEhAWlsuAuGiaytQWku5Q6WUW1sQGR1IEQRRO3VqtsQsMVmW/WmfnXN0P7w5J9/zPc/7PO/zHK2zs4fBQR+LSzEiogKjk4wGJ4nGNthK7DIXihB6uMjScpzwwgqzcwtMTM2xtv6LOpP/37t3n4EBF339P6O1t3cxMxsmvrZJTJS8JNeNzW2mZ+ZZWV0XYGvsJp+R+DWpms3Ohdl5cqAajY/PEhybZsQ3SldXL5pk6PEM4/ePMTUdYiGyyuQXBvPhZcV8eWVNXS4v/5a8vDwslu9oa7/D5tYTdvcOFXt53tPTj9bWdge3e5h+QVeCrm8kFKhkKPeSYSz+GLvdicFgIDc3F6PRSFFRMXvPjvj0z798/PQ3qbcf2D98gXb3rhufL6g6bAlJ2zv7JEVX2Tn15gOHz1McHL7k1i075tIycnIMnD17DlNhEYWFJioslXT39OIZ9PLjzVo0l/uz3PuDI0LyQxLbezw9OOZF6ndept5x/Oote/vPsVprsAmW1uoaBWgRQDn6HLKystA0jVA4wrXrN9CaGpsZGvIr2f+7GYtvEhczXI0+Yv1RAreY8ZUr1SR2kgLUwflz5zGZisjOziY9PZ0qq5U/Pv6FPxBEs9vblEw5fDnk5NMjjo5fq/XVb+958+5Pxez06XxKS82c0Ok4deorLl60KMC0tDRaWm0sR2PMR5bQamvr6e7uo0uU09kpcjWhYiQN2U2KOb5+L856ycjI5MKFClpbb3Pb0U5xcSl6IbmhoZGWFhtNTc1cvXodrab6mtjc4KebdTQK+XV1DSJPfXi9AcbGZ4hGN3A4Ojhz5hsFUlZWrpjKfUZmJibhtoyR2VymnNfsNif9IuUDwm2Pxyvi48LlGmJ4+AHekQDB4JTKV0mJWcVGGiBlSmPy87/mpOGkmqPuhA6dGIfW0dGtgB4EJkSgQ8KYJWWOLPm0pPOSbXFxCfpsvZCpp6CgUDFqbrZRX9+kvhmNBVy69AOaw9mhXPT5g18AF4ksRj+/bbEuRKIq9JcvVylz5Ht1iBnKDFoqvxfu16gEVFVZqaio5D+LLB9ykJ0XagAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/c6c1288528036ea9df3176dbafeffabf/b444b/2020.png","srcSet":"/static/c6c1288528036ea9df3176dbafeffabf/b444b/2020.png 600w","sizes":"100vw"},"sources":[{"srcSet":"/static/c6c1288528036ea9df3176dbafeffabf/9ff6b/2020.webp 600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6666666666666666}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAUCAIAAAAC64paAAAACXBIWXMAAAsTAAALEwEAmpwYAAABCUlEQVQ4y2MQVdQiGzEMJ80iCppwBOcSpRlZHZop+DSLKWnzS6v0Tpl5/da9E2cuXL1xZ/6SlXxSyvOXrlq8cp2ArBpBzaqNnX1HT57Zvmf/4ROnJk6fwyutMnHG3GlzFgri1wxBAjKqQPthSBXoYIgIUc7umTT96vVbJ06fO3X2AhABGZev3Zgxb5GwvAYhzTJAZ/cfPXF2595Duw8cASIg4/Dx072TZxLQjOFsVTCCeoEoZ3dPnH7l2q1zF6+6BYSbO3mdPnfp8tWb0+cuEiLsbGnV5q4Jx8+cO3TspLNviKmD+/4jx4+dPtc/bRZRzhaSUxeUUwMioGphBU0IW1BOfZjnKnpoBgBuRuAIvQwT7gAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"21 min read"},"layout":"","slug":"/2020/"}},"primaryTag":"speech"}},
    "staticQueryHashes": ["3170763342","3229353822"]}