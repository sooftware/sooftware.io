{
    "componentChunkName": "component---src-templates-tags-tsx",
    "path": "/tags/attention/",
    "result": {"data":{"allTagYaml":{"edges":[{"node":{"id":"speeches","description":"Some of the greatest words ever spoken.","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#282818","images":{"fallback":{"src":"/static/4dd7b5f567d2699202bc626bbcda5936/7f071/speeches-cover.jpg","srcSet":"/static/4dd7b5f567d2699202bc626bbcda5936/7a1a9/speeches-cover.jpg 750w,\n/static/4dd7b5f567d2699202bc626bbcda5936/25ec5/speeches-cover.jpg 1080w,\n/static/4dd7b5f567d2699202bc626bbcda5936/28e43/speeches-cover.jpg 1366w,\n/static/4dd7b5f567d2699202bc626bbcda5936/7f071/speeches-cover.jpg 1400w","sizes":"100vw"},"sources":[{"srcSet":"/static/4dd7b5f567d2699202bc626bbcda5936/662b3/speeches-cover.webp 750w,\n/static/4dd7b5f567d2699202bc626bbcda5936/6e6c6/speeches-cover.webp 1080w,\n/static/4dd7b5f567d2699202bc626bbcda5936/e4be3/speeches-cover.webp 1366w,\n/static/4dd7b5f567d2699202bc626bbcda5936/04d29/speeches-cover.webp 1400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4407142857142857}}}}}]},"allMarkdownRemark":{"totalCount":3,"edges":[{"node":{"excerpt":"Efficient Attention: Attention with Linear Complexities Shen Zhuoran et al. Abstract Dot-product attention은 들어오는 인풋 길이에 따라 memory…","frontmatter":{"title":"Efficient Attention Paper Review","excerpt":null,"tags":["attention","paper"],"date":"2021-07-17T10:00:00.000Z","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/2cdc9b7481cd5e517d106c8618db52d3/a2d8d/efficient_attention.png","srcSet":"/static/2cdc9b7481cd5e517d106c8618db52d3/a74b9/efficient_attention.png 750w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/63493/efficient_attention.png 1080w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/a2d8d/efficient_attention.png 1211w","sizes":"100vw"},"sources":[{"srcSet":"/static/2cdc9b7481cd5e517d106c8618db52d3/ba69e/efficient_attention.webp 750w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/f8adb/efficient_attention.webp 1080w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/a7f95/efficient_attention.webp 1211w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4706853839801816}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/f31ef/ghost.png 40w,\n/static/7ffe238930a689e103d70f234bb00199/1f8a1/ghost.png 80w,\n/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/e73fe/ghost.webp 40w,\n/static/7ffe238930a689e103d70f234bb00199/61ca6/ghost.webp 80w,\n/static/7ffe238930a689e103d70f234bb00199/507b0/ghost.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"1 min read"},"layout":"","slug":"/efficient-attention/"}}},{"node":{"excerpt":"Luna: Linear Unified Nested Attention USC + CMU + Facebook AI 2021.06 code Abstract 트랜스포머의 Multi Headed Self Attention…","frontmatter":{"title":"Luna: Linear Unified Nested Attention","excerpt":null,"tags":["attention"],"date":"2021-07-03T23:46:37.121Z","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/540ac0a1a4457065fef9e262f9962c83/af6c5/luna.png","srcSet":"/static/540ac0a1a4457065fef9e262f9962c83/a5b02/luna.png 750w,\n/static/540ac0a1a4457065fef9e262f9962c83/ace3b/luna.png 1080w,\n/static/540ac0a1a4457065fef9e262f9962c83/58836/luna.png 1366w,\n/static/540ac0a1a4457065fef9e262f9962c83/af6c5/luna.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/540ac0a1a4457065fef9e262f9962c83/6f4ad/luna.webp 750w,\n/static/540ac0a1a4457065fef9e262f9962c83/9ec3b/luna.webp 1080w,\n/static/540ac0a1a4457065fef9e262f9962c83/51e4d/luna.webp 1366w,\n/static/540ac0a1a4457065fef9e262f9962c83/3c39a/luna.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5192708333333333}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/f31ef/ghost.png 40w,\n/static/7ffe238930a689e103d70f234bb00199/1f8a1/ghost.png 80w,\n/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/e73fe/ghost.webp 40w,\n/static/7ffe238930a689e103d70f234bb00199/61ca6/ghost.webp 80w,\n/static/7ffe238930a689e103d70f234bb00199/507b0/ghost.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"post","slug":"/luna/"}}},{"node":{"excerpt":"Attention-Based Models for Speech Recognition Paper Review title http://papers.nips.cc/paper/5847-attention-based-models-for-speech…","frontmatter":{"title":"Attention-Based Models for Speech Recognition Paper Review","excerpt":null,"tags":["speech","attention","paper"],"date":"2020-01-20T10:00:00.000Z","image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/1402657e6eeeaf54425d3d5cf34998c8/0f4e3/loc-attention.png","srcSet":"/static/1402657e6eeeaf54425d3d5cf34998c8/0f4e3/loc-attention.png 681w","sizes":"100vw"},"sources":[{"srcSet":"/static/1402657e6eeeaf54425d3d5cf34998c8/c0309/loc-attention.webp 681w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4552129221732746}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/f31ef/ghost.png 40w,\n/static/7ffe238930a689e103d70f234bb00199/1f8a1/ghost.png 80w,\n/static/7ffe238930a689e103d70f234bb00199/a8b52/ghost.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/e73fe/ghost.webp 40w,\n/static/7ffe238930a689e103d70f234bb00199/61ca6/ghost.webp 80w,\n/static/7ffe238930a689e103d70f234bb00199/507b0/ghost.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"11 min read"},"layout":"","slug":"/loc-attention/"}}}]}},"pageContext":{"tag":"attention"}},
    "staticQueryHashes": ["3170763342","3229353822"]}