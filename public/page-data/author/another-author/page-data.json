{
    "componentChunkName": "component---src-templates-author-tsx",
    "path": "/author/another-author/",
    "result": {"data":{"authorYaml":{"id":"Another Author","website":"https://ghost.org/","twitter":"TryGhost","bio":"This is another test author with a profile background image","facebook":"ghost","location":"San Francisco","profile_image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#080808","images":{"fallback":{"src":"/static/c2756fa06c84564e79951c785c6a316b/5267c/alex-knight-326705-unsplash.jpg","srcSet":"/static/c2756fa06c84564e79951c785c6a316b/7284f/alex-knight-326705-unsplash.jpg 750w,\n/static/c2756fa06c84564e79951c785c6a316b/29ba9/alex-knight-326705-unsplash.jpg 1080w,\n/static/c2756fa06c84564e79951c785c6a316b/c8896/alex-knight-326705-unsplash.jpg 1366w,\n/static/c2756fa06c84564e79951c785c6a316b/5267c/alex-knight-326705-unsplash.jpg 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/c2756fa06c84564e79951c785c6a316b/57584/alex-knight-326705-unsplash.webp 750w,\n/static/c2756fa06c84564e79951c785c6a316b/984df/alex-knight-326705-unsplash.webp 1080w,\n/static/c2756fa06c84564e79951c785c6a316b/4a276/alex-knight-326705-unsplash.webp 1366w,\n/static/c2756fa06c84564e79951c785c6a316b/9c00f/alex-knight-326705-unsplash.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6666666666666666}}},"avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/a0287/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/996dd/ghost.png 40w,\n/static/7ffe238930a689e103d70f234bb00199/4ed6d/ghost.png 80w,\n/static/7ffe238930a689e103d70f234bb00199/a0287/ghost.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/3a6ff/ghost.webp 40w,\n/static/7ffe238930a689e103d70f234bb00199/1deab/ghost.webp 80w,\n/static/7ffe238930a689e103d70f234bb00199/b15f9/ghost.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}},"allMarkdownRemark":{"edges":[{"node":{"excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLMâ€¦","frontmatter":{"title":"Textless NLP","excerpt":null,"tags":["speech","nlp","paper"],"date":"2021-09-19T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/afa5c/gslm.png","srcSet":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/0dee1/gslm.png 750w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/8beaa/gslm.png 1080w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/d079a/gslm.png 1366w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/afa5c/gslm.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/a66aa/gslm.webp 750w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/65dd5/gslm.webp 1080w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/4fad6/gslm.webp 1366w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/c512e/gslm.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/Textledd NLP: Generating expressive speech from raw audio/"}}},{"node":{"excerpt":"Tokenization ë¬¸ì¥ì—ì„œ ì˜ë¯¸ìˆëŠ” ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ëŠ” ì‘ì—…ì„ ë¼ê³  í•œë‹¤. ë¬¸ì ë‹¨ìœ„ í† í°í™” ë¬¸ì ë‹¨ìœ„ë¡œ í† í°í™”ë¥¼ í•˜ëŠ” ê²ƒì´ë‹¤. í•œê¸€ ìŒì ˆ ìˆ˜ëŠ” ëª¨ë‘ 11,172ê°œì´ë¯€ë¡œ ì•ŒíŒŒë²³, ìˆ«ì, ê¸°í˜¸ ë“±ì„ ê³ ë ¤í•œë‹¤ê³  í•´ë„ ë‹¨ì–´ ì‚¬ì „ì˜ í¬ê¸°ëŠ” ê¸°ê»í•´ì•¼ 1â€¦","frontmatter":{"title":"Tokenizer","excerpt":null,"tags":["nlp"],"date":"2021-09-13T23:46:37.121Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#c8b8b8","images":{"fallback":{"src":"/static/8e92507f0141c508e4d5a30d3ca6fe53/4d1d2/writing.jpg","srcSet":"/static/8e92507f0141c508e4d5a30d3ca6fe53/6cce3/writing.jpg 750w,\n/static/8e92507f0141c508e4d5a30d3ca6fe53/fb319/writing.jpg 1080w,\n/static/8e92507f0141c508e4d5a30d3ca6fe53/6a5de/writing.jpg 1366w,\n/static/8e92507f0141c508e4d5a30d3ca6fe53/4d1d2/writing.jpg 1400w","sizes":"100vw"},"sources":[{"srcSet":"/static/8e92507f0141c508e4d5a30d3ca6fe53/d2a19/writing.webp 750w,\n/static/8e92507f0141c508e4d5a30d3ca6fe53/72f43/writing.webp 1080w,\n/static/8e92507f0141c508e4d5a30d3ca6fe53/8992a/writing.webp 1366w,\n/static/8e92507f0141c508e4d5a30d3ca6fe53/d652b/writing.webp 1400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6678571428571428}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"10 min read"},"layout":"post","slug":"/tokenizer/"}}},{"node":{"excerpt":"ì •ê·œ í‘œí˜„ì‹ ì •ê·œí‘œí˜„ì‹(regular expression)ì€ ì¼ì¢…ì˜ ë¬¸ìë¥¼ í‘œí˜„í•˜ëŠ” ê³µì‹ìœ¼ë¡œ, íŠ¹ì • ê·œì¹™ì´ ìˆëŠ” ë¬¸ìì—´ ì§‘í•©ì„ ì¶”ì¶œí•  ë•Œ ìì£¼ ì‚¬ìš©ë˜ëŠ” ê¸°ë²•ì…ë‹ˆë‹¤. ì£¼ë¡œ Prograaming Languageë‚˜ Text Editorâ€¦","frontmatter":{"title":"ì •ê·œí‘œí˜„ì‹ (regex)","excerpt":null,"tags":["nlp"],"date":"2021-09-08T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ebc4f36cae54a4a8d9eea6079daca5bc/acc2d/regex.png","srcSet":"/static/ebc4f36cae54a4a8d9eea6079daca5bc/acc2d/regex.png 699w","sizes":"100vw"},"sources":[{"srcSet":"/static/ebc4f36cae54a4a8d9eea6079daca5bc/8a3ab/regex.webp 699w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.45064377682403434}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"30 min read"},"layout":"","slug":"/regex/"}}},{"node":{"excerpt":"Streamlit The fastest way to build data apps in Python github repository: https://github.com/streamlit/streamlit tutorial: https://docsâ€¦","frontmatter":{"title":"Streamlit","excerpt":"The fastest way to build data apps in Python","tags":["web","python","open-source"],"date":"2021-08-30T10:00:00.000Z","draft":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#080808","images":{"fallback":{"src":"/static/46903c2153074058949ad5adb0612cc8/7fd08/streamlit.png","srcSet":"/static/46903c2153074058949ad5adb0612cc8/02626/streamlit.png 750w,\n/static/46903c2153074058949ad5adb0612cc8/bd00f/streamlit.png 1080w,\n/static/46903c2153074058949ad5adb0612cc8/fbd3b/streamlit.png 1366w,\n/static/46903c2153074058949ad5adb0612cc8/7fd08/streamlit.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/46903c2153074058949ad5adb0612cc8/bf0cd/streamlit.webp 750w,\n/static/46903c2153074058949ad5adb0612cc8/15fc6/streamlit.webp 1080w,\n/static/46903c2153074058949ad5adb0612cc8/2e603/streamlit.webp 1366w,\n/static/46903c2153074058949ad5adb0612cc8/24451/streamlit.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5802083333333333}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"7 min read"},"layout":"post","slug":"/streamlit/"}}},{"node":{"excerpt":"ìµœê·¼ NLP í† í¬ë‚˜ì´ì €ë¥¼ ë§Œë“œëŠ”ë° ê°€ì¥ ë§ì´ ì‚¬ìš©ë˜ëŠ”  ë¼ì´ë¸ŒëŸ¬ì™€ ì‹¤ì œ ì‚¬ìš©ì´ ê°€ì¥ ë§ì´ ë˜ëŠ”  ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œì˜ ë³€í™˜ì— ëŒ€í•œ ì½”ë“œë¥¼ ë‹´ê³  ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë‚´ìš©ì€  ë²„ì ¼ì—ì„œ ìˆ˜í–‰ë˜ì—ˆìŠµë‹ˆë‹¤. Train ì•„ë˜ ì½”ë“œëŠ” wordpiece, char-bpeâ€¦","frontmatter":{"title":"Hugging Face Tokenizers","excerpt":null,"tags":["huggingface","nlp"],"date":"2021-08-11T15:11:55.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8d818","images":{"fallback":{"src":"/static/ccbb378a7f6bb27d48ab79b74b1b4d28/5eb66/huggingface.png","srcSet":"/static/ccbb378a7f6bb27d48ab79b74b1b4d28/c65f6/huggingface.png 750w,\n/static/ccbb378a7f6bb27d48ab79b74b1b4d28/5eb66/huggingface.png 798w","sizes":"100vw"},"sources":[{"srcSet":"/static/ccbb378a7f6bb27d48ab79b74b1b4d28/2b9c0/huggingface.webp 750w,\n/static/ccbb378a7f6bb27d48ab79b74b1b4d28/1b08c/huggingface.webp 798w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9511278195488723}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"post","slug":"/tokenizers/"}}},{"node":{"excerpt":"Efficient Attention: Attention with Linear Complexities Shen Zhuoran et al. Abstract Dot-product attentionì€ ë“¤ì–´ì˜¤ëŠ” ì¸í’‹ ê¸¸ì´ì— ë”°ë¼ memoryâ€¦","frontmatter":{"title":"Efficient Attention Paper Review","excerpt":null,"tags":["attention","paper"],"date":"2021-07-17T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/2cdc9b7481cd5e517d106c8618db52d3/a2d8d/efficient_attention.png","srcSet":"/static/2cdc9b7481cd5e517d106c8618db52d3/a74b9/efficient_attention.png 750w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/63493/efficient_attention.png 1080w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/a2d8d/efficient_attention.png 1211w","sizes":"100vw"},"sources":[{"srcSet":"/static/2cdc9b7481cd5e517d106c8618db52d3/ba69e/efficient_attention.webp 750w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/f8adb/efficient_attention.webp 1080w,\n/static/2cdc9b7481cd5e517d106c8618db52d3/a7f95/efficient_attention.webp 1211w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4706853839801816}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"1 min read"},"layout":"","slug":"/efficient-attention/"}}},{"node":{"excerpt":"2021 AI ì˜¨ë¼ì¸ ê²½ì§„ëŒ€íšŒ 1ìœ„ ì´ë²ˆì— ì—´ë¦° 2021 ì¸ê³µì§€ëŠ¥ ì˜¨ë¼ì¸ ê²½ì§„ëŒ€íšŒ ëŒ€í™” ê°ì„± ë¶„ë¥˜ íƒœìŠ¤í¬ì— íšŒì‚¬ ëŒ€í‘œë¡œ ì°¸ê°€ Public / Private / Final ë¦¬ë”ë³´ë“œì—ì„œ ëª¨ë‘â€¦","frontmatter":{"title":"2021 AI ì˜¨ë¼ì¸ ê²½ì§„ëŒ€íšŒ 1ìœ„","excerpt":null,"tags":["competition","tunib"],"date":"2021-07-12T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/21d62c8654d10e5d942b1712a230ff6e/93f02/1st_ranked.png","srcSet":"/static/21d62c8654d10e5d942b1712a230ff6e/02437/1st_ranked.png 750w,\n/static/21d62c8654d10e5d942b1712a230ff6e/e8771/1st_ranked.png 1080w,\n/static/21d62c8654d10e5d942b1712a230ff6e/44ee1/1st_ranked.png 1366w,\n/static/21d62c8654d10e5d942b1712a230ff6e/93f02/1st_ranked.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/21d62c8654d10e5d942b1712a230ff6e/06597/1st_ranked.webp 750w,\n/static/21d62c8654d10e5d942b1712a230ff6e/94e4c/1st_ranked.webp 1080w,\n/static/21d62c8654d10e5d942b1712a230ff6e/4094c/1st_ranked.webp 1366w,\n/static/21d62c8654d10e5d942b1712a230ff6e/da0c3/1st_ranked.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5645833333333333}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"2 min read"},"layout":"","slug":"/2021_ai_online_competition/"}}},{"node":{"excerpt":"Luna: Linear Unified Nested Attention USC + CMU + Facebook AI 2021.06 code Abstract íŠ¸ëœìŠ¤í¬ë¨¸ì˜ Multi Headed Self Attentionâ€¦","frontmatter":{"title":"Luna: Linear Unified Nested Attention","excerpt":null,"tags":["attention"],"date":"2021-07-03T23:46:37.121Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/540ac0a1a4457065fef9e262f9962c83/af6c5/luna.png","srcSet":"/static/540ac0a1a4457065fef9e262f9962c83/a5b02/luna.png 750w,\n/static/540ac0a1a4457065fef9e262f9962c83/ace3b/luna.png 1080w,\n/static/540ac0a1a4457065fef9e262f9962c83/58836/luna.png 1366w,\n/static/540ac0a1a4457065fef9e262f9962c83/af6c5/luna.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/540ac0a1a4457065fef9e262f9962c83/6f4ad/luna.webp 750w,\n/static/540ac0a1a4457065fef9e262f9962c83/9ec3b/luna.webp 1080w,\n/static/540ac0a1a4457065fef9e262f9962c83/51e4d/luna.webp 1366w,\n/static/540ac0a1a4457065fef9e262f9962c83/3c39a/luna.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5192708333333333}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"post","slug":"/luna/"}}},{"node":{"excerpt":"GPT Understands, Too Xiao Liu et al. Tsinghua University etc. arXiv pre-print Abstract GPTë¥¼ íŒŒì¸íŠœë‹í•˜ëŠ” ë°©ë²•ì€ Narural Language Understanding (NLUâ€¦","frontmatter":{"title":"P-Tuning Paper Review","excerpt":null,"tags":["nlp","paper"],"date":"2021-05-13T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/5251bff33539be461c690325c488ea29/c0e65/p_tuning.png","srcSet":"/static/5251bff33539be461c690325c488ea29/f0b2b/p_tuning.png 750w,\n/static/5251bff33539be461c690325c488ea29/3831f/p_tuning.png 1080w,\n/static/5251bff33539be461c690325c488ea29/ec348/p_tuning.png 1366w,\n/static/5251bff33539be461c690325c488ea29/c0e65/p_tuning.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/5251bff33539be461c690325c488ea29/a4cf2/p_tuning.webp 750w,\n/static/5251bff33539be461c690325c488ea29/4e6df/p_tuning.webp 1080w,\n/static/5251bff33539be461c690325c488ea29/04ab9/p_tuning.webp 1366w,\n/static/5251bff33539be461c690325c488ea29/19b4f/p_tuning.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.23489583333333336}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/p_tuning/"}}},{"node":{"excerpt":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Yu Zhang et al., 2020 Google Research, Brain Team Referenceâ€¦","frontmatter":{"title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2021-03-17T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/7ca66667228d877c1b0d96e85b974435/ee3dd/pushing.png","srcSet":"/static/7ca66667228d877c1b0d96e85b974435/6a16f/pushing.png 750w,\n/static/7ca66667228d877c1b0d96e85b974435/ee3dd/pushing.png 928w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ca66667228d877c1b0d96e85b974435/e0c95/pushing.webp 750w,\n/static/7ca66667228d877c1b0d96e85b974435/86029/pushing.webp 928w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6142241379310345}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"3 min read"},"layout":"","slug":"/Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition/"}}},{"node":{"excerpt":"Longformer: The Long-Document Transformer Paper Code Iz Beltagy et al. Introduction íŠ¸ëœìŠ¤í¬ë¨¸ëŠ” ê¸´ ì‹œí€€ìŠ¤ëŠ” ì²˜ë¦¬í•˜ì§€ ëª»í•œë‹¤ëŠ” í•œê³„ë¥¼ ê°€ì§€ê³  ìˆìŒ ì´ìœ ëŠ” ì‹œí€€ìŠ¤ ê¸¸ì´ì— O(n^â€¦","frontmatter":{"title":"Longformer Paper Review","excerpt":null,"tags":["nlp","paper"],"date":"2021-02-06T23:46:37.121Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ef32af94bd92c05cbfebe0cb00c3966e/597e6/longformer.png","srcSet":"/static/ef32af94bd92c05cbfebe0cb00c3966e/597e6/longformer.png 512w","sizes":"100vw"},"sources":[{"srcSet":"/static/ef32af94bd92c05cbfebe0cb00c3966e/3d2a6/longformer.webp 512w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.8046875000000001}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"post","slug":"/longformer/"}}},{"node":{"excerpt":"Computer Architecture Review ì˜¤ëœë§Œì— ì»´í“¨í„° êµ¬ì¡°ì—ì„œ ë°°ìš´ ë‚´ìš©ì„ ì¡°ê¸ˆ ë³µìŠµí•´ë³´ë©° ê°ì„ ì¡ê¸° ìœ„í•¨ ì»´í“¨í„°ê°€ ì½”ë“œë¥¼ ì²˜ë¦¬í•˜ëŠ” ê³¼ì • Read Code Assembly ë³€í™˜ CPUì—ì„œ ì‹¤í–‰ CPUì—ì„œ í•˜ë‚˜ì˜ ëª…ë ¹(Ex) Addâ€¦","frontmatter":{"title":"Computer Architecture Review","excerpt":null,"tags":["cs"],"date":"2021-02-05T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/83debf50782f47536b48f20a7c0c3d46/ac5ac/computer-architecture.png","srcSet":"/static/83debf50782f47536b48f20a7c0c3d46/1d01f/computer-architecture.png 750w,\n/static/83debf50782f47536b48f20a7c0c3d46/ac5ac/computer-architecture.png 798w","sizes":"100vw"},"sources":[{"srcSet":"/static/83debf50782f47536b48f20a7c0c3d46/96ac1/computer-architecture.webp 750w,\n/static/83debf50782f47536b48f20a7c0c3d46/2afea/computer-architecture.webp 798w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.7017543859649122}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"2 min read"},"layout":"","slug":"/computer-ar-review/"}}},{"node":{"excerpt":"2020ë…„ íšŒê³  ë‹¤ì‚¬ë‹¤ë‚œí–ˆë˜ 2020ë…„ì´ ì§€ë‚˜ê³  ì–´ëŠë§ 2021ë…„ ìƒˆí•´ê°€ ë°ì•˜ìŠµë‹ˆë‹¤. ğŸ¤— ğŸ¤— ì½”ë¡œë‚˜ë¼ëŠ” ì„¸ê³„ì ì¸ ì¬ì•™ ë•Œë¬¸ì— ìƒí™œë¶€í„° ëª¨ë“ ê²Œ ë§ì´ ë‹¬ë¼ì§„ í•œ í•´ ì˜€ìŠµë‹ˆë‹¤. ì—¬íƒœê¹Œì§€â€¦","frontmatter":{"title":"2020ë…„ íšŒê³ ","excerpt":null,"tags":["retrospect"],"date":"2020-12-31T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#080808","images":{"fallback":{"src":"/static/c6c1288528036ea9df3176dbafeffabf/b444b/2020.png","srcSet":"/static/c6c1288528036ea9df3176dbafeffabf/b444b/2020.png 600w","sizes":"100vw"},"sources":[{"srcSet":"/static/c6c1288528036ea9df3176dbafeffabf/9ff6b/2020.webp 600w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6666666666666666}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"21 min read"},"layout":"","slug":"/2020/"}}},{"node":{"excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speechâ€¦","frontmatter":{"title":"EMNLP Paper Review: Speech","excerpt":null,"tags":["speech","nlp","paper"],"date":"2020-12-08T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png","srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/1206c/2020-emnlp.png 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c1998/2020-emnlp.png 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/c6087/2020-emnlp.png 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/5a68f/2020-emnlp.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/3020a90c23b0e5a906d9e9d75523071a/3e1c3/2020-emnlp.webp 750w,\n/static/3020a90c23b0e5a906d9e9d75523071a/bbc54/2020-emnlp.webp 1080w,\n/static/3020a90c23b0e5a906d9e9d75523071a/72682/2020-emnlp.webp 1366w,\n/static/3020a90c23b0e5a906d9e9d75523071a/97f4c/2020-emnlp.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.41875}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/2020 EMNLP Speech Paper Review/"}}},{"node":{"excerpt":"Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism â€‹ Mohammad Shoeybi et al. 2019. NVIDIA Corp. â€‹ Summaryâ€¦","frontmatter":{"title":"Megatron LM Paper Review","excerpt":null,"tags":["nlp","parallelism","paper"],"date":"2020-12-03T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/a4dec0b9c36035e9191658ce9647ae73/a70e6/megatron.png","srcSet":"/static/a4dec0b9c36035e9191658ce9647ae73/37b55/megatron.png 750w,\n/static/a4dec0b9c36035e9191658ce9647ae73/a70e6/megatron.png 791w","sizes":"100vw"},"sources":[{"srcSet":"/static/a4dec0b9c36035e9191658ce9647ae73/0b2ce/megatron.webp 750w,\n/static/a4dec0b9c36035e9191658ce9647ae73/c471e/megatron.webp 791w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5170670037926676}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/Megatron-lm/"}}},{"node":{"excerpt":"One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech TomÃ¡Å¡ Nekvinda, OndÅ™ej DuÅ¡ek Charles University INTERSPEECH, 202â€¦","frontmatter":{"title":"One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech Paper Review","excerpt":null,"tags":["speech","tts","paper"],"date":"2020-10-14T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/deca33714347f50cf9f1b33b2db865ef/7189c/multilingual-tts.png","srcSet":"/static/deca33714347f50cf9f1b33b2db865ef/cefb5/multilingual-tts.png 750w,\n/static/deca33714347f50cf9f1b33b2db865ef/c1615/multilingual-tts.png 1080w,\n/static/deca33714347f50cf9f1b33b2db865ef/7189c/multilingual-tts.png 1280w","sizes":"100vw"},"sources":[{"srcSet":"/static/deca33714347f50cf9f1b33b2db865ef/da87f/multilingual-tts.webp 750w,\n/static/deca33714347f50cf9f1b33b2db865ef/bd382/multilingual-tts.webp 1080w,\n/static/deca33714347f50cf9f1b33b2db865ef/2dc0b/multilingual-tts.webp 1280w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.328125}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/one-model-many-langs/"}}},{"node":{"excerpt":"RoBERTa paper / code Abstract BERTë¥¼ ì œëŒ€ë¡œ í•™ìŠµì‹œí‚¤ëŠ” ë²•ì„ ì œì•ˆ BERTëŠ” ì—„ì²­ë‚œ ëª¨ë¸ì´ì§€ë§Œ, Original BERT ë…¼ë¬¸ì—ì„œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ì— ëŒ€í•œ ì‹¤í—˜ì´ ì œëŒ€ë¡œ ì§„í–‰ë˜ì§€ ì•ŠìŒ BERTâ€¦","frontmatter":{"title":"RoBERTa Paper Review","excerpt":null,"tags":["nlp","paper"],"date":"2020-10-11T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/26b5f2f1a6d4d031c6cf36eac285256a/1be58/roberta.png","srcSet":"/static/26b5f2f1a6d4d031c6cf36eac285256a/5dae1/roberta.png 750w,\n/static/26b5f2f1a6d4d031c6cf36eac285256a/35cd7/roberta.png 1080w,\n/static/26b5f2f1a6d4d031c6cf36eac285256a/1be58/roberta.png 1134w","sizes":"100vw"},"sources":[{"srcSet":"/static/26b5f2f1a6d4d031c6cf36eac285256a/76436/roberta.webp 750w,\n/static/26b5f2f1a6d4d031c6cf36eac285256a/ce7b4/roberta.webp 1080w,\n/static/26b5f2f1a6d4d031c6cf36eac285256a/03f03/roberta.webp 1134w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.8835978835978836}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/roberta/"}}},{"node":{"excerpt":"Below is just about everything youâ€™ll need to style in the theme. Check the source code to see the many embedded elements within paragraphsâ€¦","frontmatter":{"title":"Electra Paper Review","excerpt":null,"tags":["nlp","paper"],"date":"2020-09-23T07:03:47.149Z","draft":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png","srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/c68af/electra.png 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/87f65/electra.png 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/d464a/electra.png 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/9fb02/electra.webp 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/cd76f/electra.webp 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/b7397/electra.webp 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/507b8/electra.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4479166666666667}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"post","slug":"/electra/"}}},{"node":{"excerpt":"wav2vec 2.0 : A Framework for Self-Supervised Learning of Speech Representations Alexei Baevski, Henry Zhou, Abdelrahman Mohamed, Michaelâ€¦","frontmatter":{"title":"Wav2vec 2.0 : A Framework for Self-Supervised Learning of Speech Representations","excerpt":null,"tags":["speech","paper"],"date":"2020-09-12T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ef0fb6095c0dcc78d73cfdf24bc9ac11/038c6/wav2vec2.png","srcSet":"/static/ef0fb6095c0dcc78d73cfdf24bc9ac11/e6cc4/wav2vec2.png 750w,\n/static/ef0fb6095c0dcc78d73cfdf24bc9ac11/038c6/wav2vec2.png 842w","sizes":"100vw"},"sources":[{"srcSet":"/static/ef0fb6095c0dcc78d73cfdf24bc9ac11/79bef/wav2vec2.webp 750w,\n/static/ef0fb6095c0dcc78d73cfdf24bc9ac11/daf06/wav2vec2.webp 842w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5106888361045131}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"5 min read"},"layout":"","slug":"/wav2vec2/"}}},{"node":{"excerpt":"Conformer: Convolution-augmented Transformer for Speech Recognition Anmol Gulati et al. Google Inc. INTERSPEECH, 2020 Reference Conformerâ€¦","frontmatter":{"title":"Conformer Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2020-08-30T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/5ca9b355b1dc4393c360f527478a3ba2/503d5/conformer.png","srcSet":"/static/5ca9b355b1dc4393c360f527478a3ba2/bfaac/conformer.png 750w,\n/static/5ca9b355b1dc4393c360f527478a3ba2/abf2b/conformer.png 1080w,\n/static/5ca9b355b1dc4393c360f527478a3ba2/6c19a/conformer.png 1366w,\n/static/5ca9b355b1dc4393c360f527478a3ba2/503d5/conformer.png 1890w","sizes":"100vw"},"sources":[{"srcSet":"/static/5ca9b355b1dc4393c360f527478a3ba2/1e5e2/conformer.webp 750w,\n/static/5ca9b355b1dc4393c360f527478a3ba2/77f81/conformer.webp 1080w,\n/static/5ca9b355b1dc4393c360f527478a3ba2/b9a60/conformer.webp 1366w,\n/static/5ca9b355b1dc4393c360f527478a3ba2/2837d/conformer.webp 1890w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6888888888888889}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"4 min read"},"layout":"","slug":"/conformer/"}}},{"node":{"excerpt":"ClovaCall: Korean Goal-Oriented Dialog Speech Corpus for Automatic Speech Recognition of Contact Centers image ë…¼ë¬¸ë§í¬ 2020-04-2â€¦","frontmatter":{"title":"ClovaCall Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2020-03-13T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/d7bd082afa8ae681e2420238dc3cd6d0/c2b97/clovacall.png","srcSet":"/static/d7bd082afa8ae681e2420238dc3cd6d0/51d72/clovacall.png 750w,\n/static/d7bd082afa8ae681e2420238dc3cd6d0/b9600/clovacall.png 1080w,\n/static/d7bd082afa8ae681e2420238dc3cd6d0/c2b97/clovacall.png 1322w","sizes":"100vw"},"sources":[{"srcSet":"/static/d7bd082afa8ae681e2420238dc3cd6d0/1f497/clovacall.webp 750w,\n/static/d7bd082afa8ae681e2420238dc3cd6d0/8f986/clovacall.webp 1080w,\n/static/d7bd082afa8ae681e2420238dc3cd6d0/ffe85/clovacall.webp 1322w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.23600605143721634}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"12 min read"},"layout":"","slug":"/clovacall/"}}},{"node":{"excerpt":"ã€ŒSTATE-OF-THE-ART SPEECH RECOGNITION WITH SEQUENCE-TO-SEQUENCE MODELã€ Review title https://arxiv.org/abs/1712.0176â€¦","frontmatter":{"title":"STATE-OF-THE-ART SPEECH RECOGNITION WITH SEQUENCE-TO-SEQUENCE MODEL Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2020-02-03T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/ccbbeff79541c85288ad06b096472221/8e70e/sota_speech.png","srcSet":"/static/ccbbeff79541c85288ad06b096472221/8e70e/sota_speech.png 546w","sizes":"100vw"},"sources":[{"srcSet":"/static/ccbbeff79541c85288ad06b096472221/dc201/sota_speech.webp 546w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.6465201465201466}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"12 min read"},"layout":"","slug":"/sota_sr_speech/"}}},{"node":{"excerpt":"Attention-Based Models for Speech Recognition Paper Review title http://papers.nips.cc/paper/5847-attention-based-models-for-speechâ€¦","frontmatter":{"title":"Attention-Based Models for Speech Recognition Paper Review","excerpt":null,"tags":["speech","attention","paper"],"date":"2020-01-20T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/1402657e6eeeaf54425d3d5cf34998c8/0f4e3/loc-attention.png","srcSet":"/static/1402657e6eeeaf54425d3d5cf34998c8/0f4e3/loc-attention.png 681w","sizes":"100vw"},"sources":[{"srcSet":"/static/1402657e6eeeaf54425d3d5cf34998c8/c0309/loc-attention.webp 681w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4552129221732746}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"11 min read"},"layout":"","slug":"/loc-attention/"}}},{"node":{"excerpt":"SpecAugment: ã€ŒA Simple Data Augmentation Method for Automatic Speech Recognitionã€  Review title https://arxiv.org/abs/1904.08779 Abstractâ€¦","frontmatter":{"title":"SpecAugment Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2020-01-12T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/a5b61e2900f2360216061fe9e8f8f640/4df46/specaugment.png","srcSet":"/static/a5b61e2900f2360216061fe9e8f8f640/4df46/specaugment.png 620w","sizes":"100vw"},"sources":[{"srcSet":"/static/a5b61e2900f2360216061fe9e8f8f640/cd871/specaugment.webp 620w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5919354838709677}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"20 min read"},"layout":"","slug":"/specaugment/"}}},{"node":{"excerpt":"Deep Speech: Scaling up end-to-end speech recognition title https://arxiv.org/pdf/1412.5567.pdf (Awni Hannun et al. 2014) Abstractâ€¦","frontmatter":{"title":"DeepSpeech Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2019-11-11T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/360f6a5bb171f9136086a6bf108b401d/2241d/deepspeech.png","srcSet":"/static/360f6a5bb171f9136086a6bf108b401d/2241d/deepspeech.png 541w","sizes":"100vw"},"sources":[{"srcSet":"/static/360f6a5bb171f9136086a6bf108b401d/1edf8/deepspeech.webp 541w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.9149722735674677}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"10 min read"},"layout":"","slug":"/deepspeech/"}}},{"node":{"excerpt":"ã€ŒListen, Attend and Spellã€ Review title https://arxiv.org/abs/1508.01211  (William Chan et al. 2015)  Introduction ì–´í…ì…˜ ê¸°ë°˜ Seq2seqâ€¦","frontmatter":{"title":"Listen, Attend and Spell Paper Review","excerpt":null,"tags":["speech","paper"],"date":"2019-09-20T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#e8e8e8","images":{"fallback":{"src":"/static/c6dd3a7d5b5935928a2ffb65755ccaf6/61a36/las.png","srcSet":"/static/c6dd3a7d5b5935928a2ffb65755ccaf6/61a36/las.png 625w","sizes":"100vw"},"sources":[{"srcSet":"/static/c6dd3a7d5b5935928a2ffb65755ccaf6/09f70/las.webp 625w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.192}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"8 min read"},"layout":"","slug":"/las/"}}},{"node":{"excerpt":"MFCC (Mel-Frequency Cepstral Coefficient) â€˜Voice Recognition Using MFCC Algorithmâ€™ ë…¼ë¬¸ ì°¸ê³  MFCCë€? ìŒì„±ì¸ì‹ì—ì„œ MFCC, Mel-Spectrogramâ€¦","frontmatter":{"title":"MFCC (Mel-Frequency Cepstral Coefficient)","excerpt":null,"tags":["dsp","speech"],"date":"2019-06-18T10:00:00.000Z","draft":false,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/e9157dcdd01342e368f885b8937a5d91/3a1d5/mfcc.png","srcSet":"/static/e9157dcdd01342e368f885b8937a5d91/52f05/mfcc.png 750w,\n/static/e9157dcdd01342e368f885b8937a5d91/3a1d5/mfcc.png 760w","sizes":"100vw"},"sources":[{"srcSet":"/static/e9157dcdd01342e368f885b8937a5d91/b6018/mfcc.webp 750w,\n/static/e9157dcdd01342e368f885b8937a5d91/2f184/mfcc.webp 760w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.0078947368421054}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#182828","images":{"fallback":{"src":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png","srcSet":"/static/7ffe238930a689e103d70f234bb00199/d6138/ghost.png 400w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ffe238930a689e103d70f234bb00199/416c3/ghost.webp 400w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1}}}}]},"fields":{"readingTime":{"text":"12 min read"},"layout":"","slug":"/mfcc/"}}}]}},"pageContext":{"author":"Another Author"}},
    "staticQueryHashes": ["3170763342","3229353822"]}