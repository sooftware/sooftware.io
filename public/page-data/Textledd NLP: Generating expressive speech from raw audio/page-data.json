{
    "componentChunkName": "component---src-templates-post-tsx",
    "path": "/Textledd NLP: Generating expressive speech from raw audio/",
    "result": {"data":{"logo":null,"markdownRemark":{"html":"<h1>Textless NLP: Generating expressive speech from raw audio</h1>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2102.01192\">paper</a> / <a href=\"https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm\">code / pre-train model</a> / <a href=\"https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio\">blog</a></li>\n<li>Name: Generative Spoken Language Model (GSLM)</li>\n</ul>\n<h2>Intro</h2>\n<ul>\n<li>BERT, RoBERTa, GPT-3 등 최근 몇 년간 <code class=\"language-text\">텍스트</code>에 집중된 NLP 모델들이 발전되어 왔음.</li>\n<li>이건 분명한 한계다. 텍스트에 대한 디펜던시를 깨야한다.</li>\n<li>언어 == 문자가 아니다. speech가 있다.</li>\n<li>그래서 우리 GSLM이 텍스트에 대한 디펜던시를 깰 수 있는 가능성을 보였다.</li>\n<li>음성 프롬프트 시대의 시작을 알린다.</li>\n<li>음성을 프롬프트로 주면 뒤이어서 인공지능이 말을 계속 이어서 말하는 모델의 등장!</li>\n</ul>\n<h2>Background</h2>\n<ul>\n<li>음성을 입력으로 하는 NLP 어플리케이션들은 ASR => NLP를 거쳐야 했음.</li>\n<li>ASR의 정확도가 100%가 아니기 때문에 분명한 정보의 오류가 존재함.</li>\n<li>우리는 여기서 ASR + NLP 구조가 아닌 Speech to Speech로 간다.</li>\n<li>Text나 label 없이 only 음성만으로 학습한다.</li>\n</ul>\n<h2>Textless NLP’s benefits</h2>\n<ul>\n<li>언어 상관없이 학습이 가능해질 가능성이 높아짐</li>\n<li>텍스트로 표현이 안되는 말의 뉘앙스, 감정 등의 정보를 반영할 수 있음</li>\n<li>텍스트 레이블링 혹은 ASR 학습 없이 모델을 학습할 수 있음</li>\n<li>유아들이 어떻게 언어를 배우고 말을 시작하는지를 알 수 있다(? 과연?)</li>\n<li>처음으로 텍스트 없이 audio to audio 번역 시스템이 가능해졌다!</li>\n</ul>\n<h2>Data</h2>\n<ul>\n<li>6,000시간의 Libri-Light와 LibriSpeech 데이터셋 (인코더 학습)</li>\n<li>LibriSpeech and LJSpeech (디코더(TTS System) 학습)</li>\n</ul>\n<h2>Model</h2>\n<img src=\"https://user-images.githubusercontent.com/42150335/134018698-f46507a0-c375-4f6f-a67f-63e6ca2a9240.png\" width=\"600\">  \n<ul>\n<li>Encoder (S2u)\n<ul>\n<li>Speech를 인풋으로 받아서 discrete unit(pseudo-text라고 부름)으로 인코딩</li>\n<li>unit은 k-means clustering으로 나눔.</li>\n<li>인코더로는 CPC, wav2vec 2.0, HuBERT를 사용 (좋은 acoustic encoder들이라고 보시면 됨)</li>\n</ul>\n</li>\n<li>uLM\n<ul>\n<li>unit sequence를 생성</li>\n</ul>\n</li>\n<li>Decoder (u2S)\n<ul>\n<li>TTS System (Tacotron2 사용)</li>\n</ul>\n</li>\n<li>여기서 unit(pseudo-text)은 letter or phoneme과 매핑되지는 않음.</li>\n<li>100 이상의 유닛일 때 좋은 성능을 보였으며 unit은 보통 음소보다 짧은 단위를 인코딩했음.</li>\n</ul>\n<img src=\"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241223788_398469455180920_2630499539056655858_n.jpg?_nc_cat=107&amp;ccb=1-5&amp;_nc_sid=ad8a9d&amp;_nc_ohc=rfiDlgtmTcYAX-EraG5&amp;_nc_ht=scontent-gmp1-1.xx&amp;oh=1c96a38f6af0ada3774380e4fd6110e6&amp;oe=61489C23\" width=\"600\">\n<ul>\n<li>생성한 음성은 pre-trained ASR 모델로 인식해서 성능 측정</li>\n<li>Pre-trained LM으로 텍스트 성능 측정</li>\n</ul>\n<h2>Result</h2>\n<img src=\"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241364732_225715579507676_6485051182702467200_n.jpg?_nc_cat=108&amp;ccb=1-5&amp;_nc_sid=ad8a9d&amp;_nc_ohc=h45PImsz8SkAX-kM1rz&amp;_nc_ht=scontent-gmp1-1.xx&amp;oh=88949e5b3a057a6e42b8266d03171ac7&amp;oe=61492788\" width=\"600\">\n<ul>\n<li>Unit의 수가 모델 성능에 큰 영향을 미침.</li>\n<li>Unit 수가 커질수록 Acoustic의 성능은 좋아졌음. (PER이 낮아졌다)</li>\n<li>LM 점수도 비슷한 경향이었으나, 너무 많은 unit을 사용하면 오히려 안 좋았음. (NLP에서 vocab의 적당한 사이즈가 좋은 이유와 비슷한 것 같음)</li>\n<li>어떤 인코더 모델이냐에 따라 다른 결과가 나옴. HuBERT 성능이 가장 좋았음.</li>\n<li>이렇게 자동으로 측정한 성능이 사람이 평가했을 때와 correlation이 높았음. (좋은 성능 지표)</li>\n</ul>","htmlAst":{"type":"root","children":[{"type":"element","tagName":"h1","properties":{},"children":[{"type":"text","value":"Textless NLP: Generating expressive speech from raw audio"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"element","tagName":"a","properties":{"href":"https://arxiv.org/abs/2102.01192"},"children":[{"type":"text","value":"paper"}]},{"type":"text","value":" / "},{"type":"element","tagName":"a","properties":{"href":"https://github.com/pytorch/fairseq/tree/master/examples/textless_nlp/gslm"},"children":[{"type":"text","value":"code / pre-train model"}]},{"type":"text","value":" / "},{"type":"element","tagName":"a","properties":{"href":"https://ai.facebook.com/blog/textless-nlp-generating-expressive-speech-from-raw-audio"},"children":[{"type":"text","value":"blog"}]}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Name: Generative Spoken Language Model (GSLM)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Intro"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"BERT, RoBERTa, GPT-3 등 최근 몇 년간 "},{"type":"element","tagName":"code","properties":{"className":["language-text"]},"children":[{"type":"text","value":"텍스트"}]},{"type":"text","value":"에 집중된 NLP 모델들이 발전되어 왔음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이건 분명한 한계다. 텍스트에 대한 디펜던시를 깨야한다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"언어 == 문자가 아니다. speech가 있다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"그래서 우리 GSLM이 텍스트에 대한 디펜던시를 깰 수 있는 가능성을 보였다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"음성 프롬프트 시대의 시작을 알린다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"음성을 프롬프트로 주면 뒤이어서 인공지능이 말을 계속 이어서 말하는 모델의 등장!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Background"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"음성을 입력으로 하는 NLP 어플리케이션들은 ASR => NLP를 거쳐야 했음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"ASR의 정확도가 100%가 아니기 때문에 분명한 정보의 오류가 존재함."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"우리는 여기서 ASR + NLP 구조가 아닌 Speech to Speech로 간다."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Text나 label 없이 only 음성만으로 학습한다."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Textless NLP’s benefits"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"언어 상관없이 학습이 가능해질 가능성이 높아짐"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"텍스트로 표현이 안되는 말의 뉘앙스, 감정 등의 정보를 반영할 수 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"텍스트 레이블링 혹은 ASR 학습 없이 모델을 학습할 수 있음"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"유아들이 어떻게 언어를 배우고 말을 시작하는지를 알 수 있다(? 과연?)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"처음으로 텍스트 없이 audio to audio 번역 시스템이 가능해졌다!"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Data"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"6,000시간의 Libri-Light와 LibriSpeech 데이터셋 (인코더 학습)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"LibriSpeech and LJSpeech (디코더(TTS System) 학습)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Model"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://user-images.githubusercontent.com/42150335/134018698-f46507a0-c375-4f6f-a67f-63e6ca2a9240.png","width":600},"children":[]},{"type":"text","value":"  \n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Encoder (S2u)\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Speech를 인풋으로 받아서 discrete unit(pseudo-text라고 부름)으로 인코딩"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"unit은 k-means clustering으로 나눔."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"인코더로는 CPC, wav2vec 2.0, HuBERT를 사용 (좋은 acoustic encoder들이라고 보시면 됨)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"uLM\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"unit sequence를 생성"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Decoder (u2S)\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"TTS System (Tacotron2 사용)"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"여기서 unit(pseudo-text)은 letter or phoneme과 매핑되지는 않음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"100 이상의 유닛일 때 좋은 성능을 보였으며 unit은 보통 음소보다 짧은 단위를 인코딩했음."}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241223788_398469455180920_2630499539056655858_n.jpg?_nc_cat=107&ccb=1-5&_nc_sid=ad8a9d&_nc_ohc=rfiDlgtmTcYAX-EraG5&_nc_ht=scontent-gmp1-1.xx&oh=1c96a38f6af0ada3774380e4fd6110e6&oe=61489C23","width":600},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"생성한 음성은 pre-trained ASR 모델로 인식해서 성능 측정"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Pre-trained LM으로 텍스트 성능 측정"}]},{"type":"text","value":"\n"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"h2","properties":{},"children":[{"type":"text","value":"Result"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"img","properties":{"src":"https://scontent-gmp1-1.xx.fbcdn.net/v/t39.2365-6/241364732_225715579507676_6485051182702467200_n.jpg?_nc_cat=108&ccb=1-5&_nc_sid=ad8a9d&_nc_ohc=h45PImsz8SkAX-kM1rz&_nc_ht=scontent-gmp1-1.xx&oh=88949e5b3a057a6e42b8266d03171ac7&oe=61492788","width":600},"children":[]},{"type":"text","value":"\n"},{"type":"element","tagName":"ul","properties":{},"children":[{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Unit의 수가 모델 성능에 큰 영향을 미침."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"Unit 수가 커질수록 Acoustic의 성능은 좋아졌음. (PER이 낮아졌다)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"LM 점수도 비슷한 경향이었으나, 너무 많은 unit을 사용하면 오히려 안 좋았음. (NLP에서 vocab의 적당한 사이즈가 좋은 이유와 비슷한 것 같음)"}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"어떤 인코더 모델이냐에 따라 다른 결과가 나옴. HuBERT 성능이 가장 좋았음."}]},{"type":"text","value":"\n"},{"type":"element","tagName":"li","properties":{},"children":[{"type":"text","value":"이렇게 자동으로 측정한 성능이 사람이 평가했을 때와 correlation이 높았음. (좋은 성능 지표)"}]},{"type":"text","value":"\n"}]}],"data":{"quirksMode":false}},"excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLM…","fields":{"readingTime":{"text":"4 min read"}},"frontmatter":{"title":"Textless NLP","userDate":"19 September 2021","date":"2021-09-19T10:00:00.000Z","tags":["speech","nlp","paper"],"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#f8f8f8","images":{"fallback":{"src":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/afa5c/gslm.png","srcSet":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/0dee1/gslm.png 750w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/8beaa/gslm.png 1080w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/d079a/gslm.png 1366w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/afa5c/gslm.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/b91fe939e42bcc0b6f0c076dca98fcc8/a66aa/gslm.webp 750w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/65dd5/gslm.webp 1080w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/4fad6/gslm.webp 1366w,\n/static/b91fe939e42bcc0b6f0c076dca98fcc8/c512e/gslm.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5625}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"children":[{"gatsbyImageData":{"layout":"fullWidth","backgroundColor":"#181818","images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/2456b/soohwan.png 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/ab12d/soohwan.png 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/2584f/soohwan.png 120w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65256/soohwan.webp 40w,\n/static/a2699b4a2f164aa71106535e018ceafc/c6b8d/soohwan.webp 80w,\n/static/a2699b4a2f164aa71106535e018ceafc/03d15/soohwan.webp 120w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.25}}]}}]}},"relatedPosts":{"totalCount":20,"edges":[{"node":{"id":"f8857a8d-9121-5e23-91bc-3fbe4f090418","excerpt":"Textless NLP: Generating expressive speech from raw audio paper / code / pre-train model / blog Name: Generative Spoken Language Model (GSLM…","frontmatter":{"title":"Textless NLP","date":"2021-09-19T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/Textledd NLP: Generating expressive speech from raw audio/"}}},{"node":{"id":"93dec710-458c-531f-acbc-28d14f762768","excerpt":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Yu Zhang et al., 2020 Google Research, Brain Team Reference…","frontmatter":{"title":"Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition Paper Review","date":"2021-03-17T10:00:00.000Z"},"fields":{"readingTime":{"text":"3 min read"},"slug":"/Pushing the Limits of Semi-Supervised Learning for Automatic Speech Recognition/"}}},{"node":{"id":"127c2cf6-c23b-5410-a480-70de1d98ce87","excerpt":"PORORO Text-To-Speech (TTS) 얼마전에 저희 팀에서 공개한 PORORO: Platform Of neuRal mOdels for natuRal language prOcessing 라이브러리에 제가 공들여만든 TTS…","frontmatter":{"title":"PORORO Text-To-Speech (TTS)","date":"2021-02-16T10:00:00.000Z"},"fields":{"readingTime":{"text":"1 min read"},"slug":"/pororo-tts/"}}},{"node":{"id":"a4f99081-c696-5b06-85b1-c2268aed1215","excerpt":"EMNLP Paper Review: Speech Adaptive Feature Selection for End-to-End Speech Translation (Biao Zhang et al) Incremental Text-to-Speech…","frontmatter":{"title":"EMNLP Paper Review: Speech","date":"2020-12-08T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/2020 EMNLP Speech Paper Review/"}}},{"node":{"id":"e1128eb2-c5b3-55e1-83ef-3b6478bb7d7b","excerpt":"One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech Tomáš Nekvinda, Ondřej Dušek Charles University INTERSPEECH, 202…","frontmatter":{"title":"One Model, Many Languages: Meta-learning for Multilingual Text-to-Speech Paper Review","date":"2020-10-14T10:00:00.000Z"},"fields":{"readingTime":{"text":"4 min read"},"slug":"/one-model-many-langs/"}}}]}},"pageContext":{"slug":"/Textledd NLP: Generating expressive speech from raw audio/","prev":{"excerpt":"이번에 저희 튜닙에서 공들여 만든 TUNiB Electra 모델을 공개했습니다 !! 🎉 🎉 이번 공개에서는 한-영 bilingual 모델과 한국어 모델을 각각 Small/Base 사이즈로 공개했으며, HuggingFace transformers…","frontmatter":{"title":"TUNiB Electra 공개","tags":["huggingface","nlp","open-source"],"date":"2021-09-18T15:11:55.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAJCAYAAAAywQxIAAAACXBIWXMAAAsTAAALEwEAmpwYAAABZElEQVQoz02S2arCQBBE8/9flHdBIu5bcItG1OCCcU80asp7GgZuYOjpnqrqLV5Zlvp8Pvp+v3q9Xnq/33o+n3o8HsrzXGmaajgcms87/u120/V61eVyMQunKAqh5env2+12SpJEURRpuVxqsVjofr+bMAREVquV4jg2n88VQZyEcPg8lGezmYkSRBhitVqV7/vqdrs6nU7abDbabrcaDAYKgkCVSkVhGBp+Op1qMplYpR5Z1uu1gRFywgjM53Or+Hw+G5FqaJfqsRQDDmFE0bKWIdAKlQA8Ho/WLm0xO+5g9vu9YZgl882yTIfDwYqAYy0jwCMkANwRQcAlAsM7lSHoFsLBB+8Se5TKXBgs8xqPx3bv9/tmaYd3FvY/3uv1NBqN1G63zcJlJB4OIAAE6/W6ms2mCWHdqdVq6nQ69t5qtcwHT4w7cXZggo1Gw0QhAiYrFjDLcL8VM3SHGJZlslR8RvEDFpSXtUMvB8QAAAAASUVORK5CYII="},"images":{"fallback":{"src":"/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png","srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/c68af/electra.png 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/87f65/electra.png 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/d464a/electra.png 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/59ccb/electra.png 1920w","sizes":"100vw"},"sources":[{"srcSet":"/static/7ccdb9951c9d362c8a3548e8c2a87231/9fb02/electra.webp 750w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/cd76f/electra.webp 1080w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/b7397/electra.webp 1366w,\n/static/7ccdb9951c9d362c8a3548e8c2a87231/507b8/electra.webp 1920w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.4479166666666667}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"2 min read"},"layout":"post","slug":"/tunib_electra/"}},"next":{"excerpt":"React 기반 개인 웹페이지 배포하기 이번 글에서는 react…","frontmatter":{"title":"React 기반 개인 웹페이지 배포하기 (gatsby)","tags":["react","web"],"date":"2021-09-22T10:00:00.000Z","draft":false,"excerpt":null,"image":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAALCAYAAAB/Ca1DAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC70lEQVQozzWSS29TVxSFj31t32v7On5i+9rxG5PYNw0xsdMkdpLGiQ0JNm4dHOVBE8UhkIAQhdAQ9UFRUyBFQrRiAFIlJBh00KqzSu0P6KCD/oD+m6/XljrYOnvr7LP22uss8fDoHmudFS6MFhhweIiHEvi8YaxWFYusIiSFpBbixVGX1UuzCGHB6fTgPjNIIFvk+dt3XNu7hVVxYXP5EGutBulwgutXP6ZRq5NJDuNQ3MYjL5LFjslqpz6W5ZfvbvN4vU7Ko3ImPkShfBGTI0jxoyu8fPcrmZESiiuA6Gys8s2j+9y5sUZp/EMSqWFcDi+K3GPoQpjsXM5n+PenE/5+/oApzU+2NMuF6XnUTJmdk7f88P5nGmt7BnsJcf/uDgebqyTDGpmIhtvuYFTXyWbOsTxRYq5S4dvrm/z+9CF/Pr5DazjJ2dkGiZwhUShF894Jj16+Jl7uYNOGEQvFPK2Lc7x/c8qbH5/SWK6RyxsXwsxJd53fTo/5/vAGfzw75K+vD6imI/g+mMYdSfcZFZsbLH/5Ct/CJuGJOuKro32OPvu0r+Gt7Q2O725Tn6tgsbo43W7zz4sHHLSaLBV1bi5OYpftuEIx3MbHSRYFfzpHrb3F/t4utw/2EfVykS8+3+HJYZfqeZ2zgzG0UByzpHJ8rcOTboeAUQuh0Gh9QjqVxSxknIbOkqIS8AepTM7Qaq5zc2sXsXWlxngyQ7M+z+5SjalsjlAwatjGSX4o328e0Qv99VbaHaanKkYu8A74DbAQPnWAmbFxLs23WakuIEr6edaXqgwFB2kXRtiozpAJBLDbnH3P9bSUDC9arA4sZgXZGCTbVJLRBF7Dd75AmJlkBN2ncnV6DJGPpVicnOCwfZnuYpnV+Qp66hyWHohkRzLJWC2OfvTqXvRyk7D1T3dAI6YFccgykWgUUcykjDVTbFUKLOZS1EbzjCXj6Om00aj1V+0x+x+sN8hsDJHMMjbD9CGPH93jIxuLkouG+Q9U7F12MgnUIAAAAABJRU5ErkJggg=="},"images":{"fallback":{"src":"/static/ddaa4cb6857e989e32ffc466cf76e8a5/7c984/gatsby.png","srcSet":"/static/ddaa4cb6857e989e32ffc466cf76e8a5/5b584/gatsby.png 750w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/c1f05/gatsby.png 1080w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/7c984/gatsby.png 1123w","sizes":"100vw"},"sources":[{"srcSet":"/static/ddaa4cb6857e989e32ffc466cf76e8a5/73e0d/gatsby.webp 750w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/9fede/gatsby.webp 1080w,\n/static/ddaa4cb6857e989e32ffc466cf76e8a5/d4610/gatsby.webp 1123w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":0.5253784505788067}}},"author":[{"id":"Soohwan Kim","bio":"Co-founder and AI engineer of TUNiB.","avatar":{"childImageSharp":{"gatsbyImageData":{"layout":"fullWidth","placeholder":{"fallback":"data:image/png;base64,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"},"images":{"fallback":{"src":"/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png","srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/65307/soohwan.png 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/bf8e0/soohwan.png 1080w","sizes":"100vw"},"sources":[{"srcSet":"/static/a2699b4a2f164aa71106535e018ceafc/f6200/soohwan.webp 750w,\n/static/a2699b4a2f164aa71106535e018ceafc/529f6/soohwan.webp 1080w","type":"image/webp","sizes":"100vw"}]},"width":1,"height":1.2462962962962962}}}}]},"fields":{"readingTime":{"text":"15 min read"},"layout":"","slug":"/react_homepage/"}},"primaryTag":"speech"}},
    "staticQueryHashes": ["3170763342","3229353822"]}